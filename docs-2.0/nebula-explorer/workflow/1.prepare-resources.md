# 资源配置

使用工作流之前，需要进行资源配置，包括{{nebula.name}}配置、HDFS 配置和{{plato.name}}配置。

## 前提条件

- 已部署 {{plato.release}} 或以上版本的{{plato.name}}。详情参见[{{plato.name}}](../..//graph-computing/nebula-analytics.md)。
- 已配置并启动 Dag Controller。详情参见[部署{{explorer.name}}](../deploy-connect/ex-ug-deploy.md)。

## 操作步骤

1. 在{{explorer.name}}页面顶部的导航栏中，单击 **Workflow**。

2. 在页面右上角单击**工作流配置**。

3. 配置如下资源：

  ![workflow_configuration](https://docs-cdn.nebula-graph.com.cn/figures/workflow_configuration_230522_cn.png)

  - 悦数 配置

    执行图查询或写入图计算结果的 Graph 服务地址。默认为登录 Explorer 使用的 Graph 服务，无法修改。可以设置三种服务的超时时间。

  - DAG 配置

    执行图计算的 Dag Controller 的相关配置。

    - 用户名：固定为`vesoft`，无需修改。
    - 数据路径：Analytics 数据目录，NFS 服务的共享目录。工作流默认使用 NFS 方式存储图计算结果，但是需要用户手动安装 NFS 并挂载目录。
    - SSH 免密私钥路径：Dag Controller 所在机器的私钥文件路径。用于机器间 SSH 免密登录。

  - 悦数 Analytics 节点配置

    添加执行图计算的 NebulaGraph Analytics 地址。

    - Nebula Analytics 节点 IP 地址：填写新的 Analytics 节点 IP 地址。
    - 用户名：默认为`vesoft`，无需修改。
    - Analytics 节点 SSH 端口号：默认为`22`。
    - Analytics 节点用户 SSH 免密私钥路径：用于机器间 SSH 免密登录。默认为`~/.ssh/id_rsa`。
    - Analytics 节点本地数据目录：默认为`~/analytics-data`。
    - Analytics 节点算法脚本路径：默认为`~/nebula-analytics/scripts/run_algo.sh`。

  - NFS 配置

    !!! note

        用户需要自行将 NFS Server 部署在 Dag Controller 所在机器上并配置共享目录，然后将 NFS Client 部署在所有 Analytics 节点机器上并挂载共享目录。

    默认开启，任务运行结果将保存至本地。用户可以修改结果的保存路径。

  - HDFS 配置（可选）

    默认情况下使用的是 NFS 保存图计算结果，如果需要使用 HDFS，请先在 Analytics 所在机器上安装 HDFS 客户端，该配置才能生效。

    - HDFS 名称：填写 HDFS 配置名称，方便区分不同 HDFS 配置。
    - HDFS 路径：即`fs.defaultFS`配置。支持配置保存路径，例如`hdfs://192.168.8.100:9000/test`。
    - HDFS 用户名：使用 HDFS 的用户名称。

4. 配置完成后，单击**保存**。

5. 在右上角单击**配置检查**，然后单击**开始检查**，检查配置是否正常。
